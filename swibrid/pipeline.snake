import os

shell.executable("/bin/bash")
shell.prefix("set -e pipefail;")


rule all:
  input:
     expand('plots/{sample}_reads.png',sample=config['SAMPLES']),
     expand('plots/{sample}_gaps.png',sample=config['SAMPLES']),
     'collect/{0}_stats.csv'.format(config['STUDY'])


rule demux:
  input:
    config['INPUT']
  output:
    fastq=expand('fastq/{sample}.fastq.gz',sample=config['SAMPLES']),
    info=expand('info/{sample}_info.csv',sample=config['SAMPLES'])
  params:
    sample_sheet=config['SAMPLE_SHEET'],
    barcodes_primers=config['BARCODES_PRIMERS']
  threads: 4
  resources:
    mem_mb=32000,
    time='08:00:00'
  conda:
    config['ENV']
  log: "logs/all/demux.log"  
  shell:
    r"""
    mkdir -p demux/out fastq info
    cat {params.barcodes_primers} | makeblastdb -in - -title "barcodes_primers" -out demux/barcodes_primers -input_type fasta -dbtype nucl 2> {log}
    gunzip -c {input} | awk '{{if(NR%4==1) {{printf(">%s\n",substr($0,2));}} else if(NR%4==2) print;}}' | blastn -db demux/barcodes_primers -query - -task blastn-short -max_target_seqs 50 -outfmt "6 saccver qaccver slen qlen pident length qstart qend evalue" -gapopen 5 -gapextend 2 -reward 3 -penalty -4 -evalue 1 -num_threads 1 -perc_identity 50 > demux/blast_output.txt 2>> {log}
    swibrid demultiplex -i {input} -b demux/blast_output.txt -f demux/summary.png --collapse -o demux/out -r demux/stats.csv --split-reads -s {params.sample_sheet} -c 50 2>> {log}
    ln -rfs demux/out/*.fastq.gz fastq
    ln -rfs demux/out/*_info.csv info
    """


rule filter:
  input:
    fastq='fastq/{sample}.fastq.gz',
    info='info/{sample}_info.csv'
  output:
    fasta='filter/{sample}.fasta',
    csv='filter/{sample}.csv'
  params:
    minlength=config['MINLENGTH'],
    complete=lambda wildcards: "--only-complete" if 'plasmid' not in wildcards.sample else "",
    internal=lambda wildcards: "--keep-internal" if ('exon' in wildcards.sample or 'plasmid' in wildcards.sample) else ""
  threads: 1
  resources:
    mem_mb=4000,
    time='04:00:00'
  conda:
    config['ENV']
  log: "logs/filter/{sample}.log"
  shell:
    r"""
    mkdir -p filter
    swibrid filter_reads -i {input.fastq} -o {output.fasta} --info {input.info} --stats {output.csv} --min-length {params.minlength} {params.complete} {params.internal} 2> {log}
    """


rule last:
  input:
    'filter/{sample}.fasta'
  output:
    maf='align/{sample}.maf',
    par='align/{sample}_last_pars.npz'
  params:
    index=config['LAST_INDEX']
  threads: 4
  resources:
    mem_mb=32000,
    time='08:00:00'
  conda:
    config['ENV']
  log: "logs/last/{sample}.log"
  shell:
    r"""
    mkdir -p align
    last-train -P4 {params.index} {input} > align/{wildcards.sample}.par  2> {log}
    lastal -P4 -p align/{wildcards.sample}.par {params.index} {input} | last-split -m1e-6 | grep -v "^p" > {output.maf} 2>> {log}
    swibrid get_alignment_pars  -i align/{wildcards.sample}.par -o {output.par} 2>> {log}
    """


rule minimap:
  input:
    'filter/{sample}.fasta'
  output:
    sam='align/{sample}.sam',
    par='align/{sample}_minimap_pars.npz'
  params:
    index=config['MINIMAP_INDEX'],
    reference=config['REFERENCE']
  threads: 4
  resources:
    mem_mb=32000,
    time='08:00:00'
  conda:
    config['ENV']
  log: "logs/minimap/{sample}.log"
  shell:
    r"""
    mkdir -p align
    minimap2 -a -x map-ont -t {threads} --secondary=no --sam-hit-only {params.index} {input} > {output.sam} 2> {log}
    swibrid get_alignment_pars -i {output.sam} -o {output.par} -r {params.reference} 2>> {log}
    """


rule telo:
  input:
    'filter/{sample}.fasta'
  output:
    'telo/{sample}.out'
  params:
    telo_repeat=config['TELO_REPEAT']
  threads: 1
  resources:
    mem_mb=16000,
    time='04:00:00'
  conda:
    config['ENV']
  log: "logs/telo/{sample}.log"
  shell:
    r"""
    mkdir -p telo
    echo -e "qseqid\tslen\tqlen\tpident\tlength\tqstart\tqend\tevalue" > {output}
    blastn -subject {params.telo_repeat} -query {input} -task blastn-short -outfmt "6 qseqid slen qlen pident length qstart qend evalue" -gapopen 5 -gapextend 2 -reward 3 -penalty -4 -evalue 1 -perc_identity 75 -dust no | uniq >> {output} 2> {log}
    """


rule process:
  input:
    alignments='align/{sample}.maf' if config['ALIGNER']=='LAST' else 'align/{sample}.sam',
    telo='telo/{sample}.out',
  output:
    out='process/{sample}.out',
    stats='process/{sample}.csv',
    fasta='process/{sample}.fasta.gz'
  params:
    switch=config['SWITCH'],
    switch_anno=config['SWITCH_ANNOTATION'],
    min_cov=lambda wildcards: ".4" if 'plasmid' in wildcards.sample else ".9",
    blacklist_regions=lambda x: "--blacklist_regions="+config['BLACKLIST_REGIONS'] if 'BLACKLIST_REGIONS' in config else ""
  threads: 1
  resources:
    mem_mb=16000,
    time='04:00:00'
  conda:
    config['ENV']
  log: "logs/process/{sample}.log"
  shell:
    r"""
    mkdir -p process
    swibrid process_alignments --alignments {input.alignments} --switch_coords {params.switch} --switch_annotation {params.switch_anno} --outfile {output.out} --stats {output.stats} --min_cov {params.min_cov} --telo {input.telo} --telo_cutoff 90 --sequences {output.fasta} {params.blacklist_regions} 2> {log}
    """


rule inserts:
  input:
    processed='process/{sample}.out',
    fasta='filter/{sample}.fasta'
  output:
    tsv='inserts/{sample}_inserts.tsv',
    bed='inserts/{sample}_inserts.bed',
  params:
    switch=config['SWITCH'],
    annotation=config['ANNOTATION'],
    switch_anno=config['SWITCH_ANNOTATION'],
  threads: 1
  resources:
    mem_mb=16000,
    time='01:00:00'
  conda:
    config['ENV']
  log: "logs/inserts/{sample}.log"
  shell:
    r"""
    mkdir -p inserts
    swibrid create_bed --raw_reads {input.fasta} --processed_reads {input.processed} --bed {output.bed} --switch_coords {params.switch} --annotation {params.annotation} --switch_annotation {params.switch_anno} --outfile {output.tsv} 2> {log}
    """

def increase_mem (wildcards, attempt):
  return 32000*attempt

def get_partition (wildcards, attempt):
  return 'medium' # if attempt <= 5 else 'highmem')


rule msa:
  input:
    coords='process/{sample}.out',
    sequences='process/{sample}.fasta.gz',
  output:
    msa='msa/{sample}_msa.npz',
    out='msa/{sample}.csv'
  params:
    switch=config['SWITCH'],
    switch_annotation=config['SWITCH_ANNOTATION'],
    nmax=config['NMAX']
  threads: 1
  resources:
    mem_mb=increase_mem,
    time='08:00:00',
    partition=get_partition
  conda:
    config['ENV']
  log: "logs/msa/{sample}.log"
  shell:
    r"""
    mkdir -p msa
    swibrid construct_msa --coords {input.coords} --sequences {input.sequences} --msa {output.msa} --switch_coords {params.switch} --switch_annotation {params.switch_annotation} --out {output.out} --use_orientation --nmax {params.nmax} 2> {log}
    """


rule gaps:
  input:
    msa='msa/{sample}_msa.npz'
  output:
    gaps='gaps/{sample}_gaps.npz'
  params:
  threads: 1
  resources:
    mem_mb=increase_mem,
    time='08:00:00',
    partition=get_partition
  conda:
    config['ENV']
  log: "logs/gaps/{sample}.log"
  shell:
    r"""
    mkdir -p gaps
    swibrid get_gaps --msa {input.msa} -o {output.gaps} 2> {log}
    """


rule linkage:
  input:
    msa='msa/{sample}_msa.npz',
    gaps='gaps/{sample}_gaps.npz'
  output:
    linkage='linkage/{sample}_linkage.npz'
  params:
    nmax=config['NMAX'],
    max_gap=config['MAX_GAP'],
    metric=config['CLUSTERING_METRIC'],
    method=config['CLUSTERING_METHOD']
  threads: 8
  resources:
    mem_mb=increase_mem,
    time='48:00:00',
    partition=get_partition,
  conda:
    config['ENV']
  log: "logs/linkage/{sample}.log"
  shell:
    r"""
    mkdir -p linkage
    swibrid construct_linkage --msa {input.msa} --gaps {input.gaps} --max_gap {params.max_gap} --metric {params.metric} --method {params.method} --nmax {params.nmax} --n_threads {threads} --linkage {output.linkage}  --method {params.method} 2> {log}
    """


rule cluster:
  input:
    linkage='linkage/{sample}_linkage.npz',
    info='msa/{sample}.csv'
  output:
    cluster='cluster/{sample}_clustering.csv',
    stats='cluster/{sample}_stats.csv',
    scanning='cluster/{sample}_scanning.csv'
  params:
    cutoff=config['CLUSTERING_CUTOFF']
  threads: 1
  resources:
    mem_mb=increase_mem,
    time='08:00:00',
    partition=get_partition
  conda:
    config['ENV']
  log: "logs/cluster/{sample}.log"
  shell:
    r"""
    mkdir -p cluster
    swibrid find_clusters -l {input.linkage} -i {input.info} -o {output.cluster} -s {output.stats} --scanning {output.scanning} -f {params.cutoff} 2> {log}
    """


rule variants:
  input:
    msa='msa/{sample}_msa.npz',
    clustering='cluster/{sample}_clustering.csv',
    pars='align/{sample}_last_pars.npz' if config['ALIGNER']=='LAST' else 'align/{sample}_minimap_pars.npz',
  output:
    txt='variants/{sample}_variants.txt',
    mat='variants/{sample}_variants.npz',
    ht='variants/{sample}_haplotypes.csv'
  params:
    switch=config['SWITCH'],
    switch_annotation=config['SWITCH_ANNOTATION'],
    reference=config['REFERENCE'],
    variant_annotation=config['VARIANT_ANNOTATION']
  threads: 1
  resources:
    mem_mb=increase_mem,
    time='04:00:00',
    partition=get_partition
  conda:
    config['ENV']
  log: "logs/variants/{sample}.log"
  shell:
    r"""
    mkdir -p variants
    swibrid find_variants --msa {input.msa} --switch_coords {params.switch} --switch_annotation {params.switch_annotation} --clustering {input.clustering} --reference {params.reference} --pars {input.pars} -o {output.txt} -m {output.mat} --haplotypes {output.ht} --variant_annotation {params.variant_annotation} 2> {log}
    """


rule homology:
  output:
    'gaps/homology.npz'
  params:
    switch=config['SWITCH'],
    switch_annotation=config['SWITCH_ANNOTATION'],
    binsize=config['BINSIZE'],
    genome=config['REFERENCE']
  threads: 1
  resources:
    mem_mb=32000,
    time='4:00:00',
    partition='short'
  conda:
    config['ENV']
  log: "logs/all/homology.log"
  shell:
    r"""
    mkdir -p gaps
    swibrid get_switch_homology --switch_coords {params.switch} --switch_annotation {params.switch_annotation} --binsize {params.binsize} --genome {params.genome} -o {output} 2> {log}
    """


rule motifs:
  output:
    'gaps/motifs.npz'
  params:
    switch=config['SWITCH'],
    switch_annotation=config['SWITCH_ANNOTATION'],
    binsize=config['BINSIZE'],
    genome=config['REFERENCE']
  threads: 1
  resources:
    mem_mb=32000,
    time='4:00:00',
    partition='short'
  conda:
    config['ENV']
  log: "logs/all/motifs.log"
  shell:
    r"""
    mkdir -p gaps
    swibrid get_switch_motifs --switch_coords {params.switch} --switch_annotation {params.switch_annotation} --binsize {params.binsize} --genome {params.genome} -o {output}  2> {log}
    """


rule analyze_clustering:
  input:
    msa='msa/{sample}_msa.npz',
    gaps='gaps/{sample}_gaps.npz',
    clustering='cluster/{sample}_clustering.csv',
    stats='cluster/{sample}_stats.csv',
    inserts='inserts/{sample}_inserts.tsv',
  output:
    'cluster/{sample}_analysis.csv'
  params:
    switch=config['SWITCH'],
    switch_annotation=config['SWITCH_ANNOTATION'],
    max_gap=config['MAX_GAP']
  threads: 1
  resources:
    mem_mb=increase_mem,
    time='08:00:00',
    partition=get_partition
  conda:
    config['ENV']
  log: "logs/cluster/{sample}_analysis.log"
  shell:
    r"""
    swibrid analyze_clustering -o {output} --msa {input.msa} --gaps {input.gaps} --max_gap {params.max_gap} --clustering {input.clustering} --switch_coords {params.switch} --switch_annotation {params.switch_annotation} --inserts {input.inserts} --clustering_stats {input.stats} --adjust_size 2> {log}
    """


rule gap_stats:
  input:
    gaps='gaps/{sample}_gaps.npz',
    clustering='cluster/{sample}_clustering.csv',
    stats='cluster/{sample}_stats.csv',
    analysis='cluster/{sample}_analysis.csv',
    homology='gaps/homology.npz',
    motifs='gaps/motifs.npz'
  output:
    stats='gaps/{sample}_stats.csv',
    plot='plots/{sample}_gaps.png'
  params:
    switch=config['SWITCH'],
    switch_annotation=config['SWITCH_ANNOTATION'],
    binsize=config['BINSIZE'],
    max_gap=config['MAX_GAP'],
    weights=config['WEIGHTS']
  threads: 1
  resources:
    mem_mb=increase_mem,
    time='4:00:00',
  conda:
    config['ENV']
  log: "logs/gaps/{sample}_stats.log"
  shell:
    r"""
    mkdir -p gaps
    swibrid get_gap_stats -g {input.gaps} -c {input.clustering} -s {input.stats} -a {input.analysis} -b {params.binsize} --max_gap {params.max_gap} --homology {input.homology} --motifs {input.motifs} --switch_coords {params.switch} --switch_annotation {params.switch_annotation} -o {output.stats} --weights {params.weights} --plot {output.plot} --sample {wildcards.sample} 2> {log}
    """


rule plot_clustering:
  input:
    process='process/{sample}.out',
    info='info/{sample}_info.csv',
    clustering='cluster/{sample}_clustering.csv',
    linkage='linkage/{sample}_linkage.npz',
    scanning='cluster/{sample}_scanning.csv',
    msa='msa/{sample}_msa.npz',
    stats='cluster/{sample}_stats.csv',
    variants_table='variants/{sample}_variants.txt',
    variants_matrix='variants/{sample}_variants.npz',
    haplotypes='variants/{sample}_haplotypes.csv'
  output:
    'plots/{sample}_reads.png'
  params:
    switch=config['SWITCH'],
    annotation=config['ANNOTATION'],
    switch_annotation=config['SWITCH_ANNOTATION'],
  threads: 1
  resources:
    mem_mb=increase_mem,
    time='04:00:00',
    partition=get_partition
  conda:
    config['ENV']
  log: "logs/plots/{sample}.log"
  shell:
    r"""
    mkdir -p plots
    swibrid plot_clustering --msa {input.msa} --figure {output} --linkage {input.linkage} --info {input.info}  --clustering_results {input.clustering} --switch_annotation {params.switch_annotation} --switch_coords {params.switch} --annotation {params.annotation} --color_by cluster --coords {input.process} --show_inserts --clustering_stats {input.stats} --sample {wildcards.sample} --variants_table {input.variants_table} --variants_matrix {input.variants_matrix} --dpi 500 --haplotypes {input.haplotypes} 2> {log}
    """


rule summary:
  input:
    info='info/{sample}_info.csv',
    filter='filter/{sample}.csv',
    process='process/{sample}.csv',
    clustering='cluster/{sample}_clustering.csv',
    scanning='cluster/{sample}_scanning.csv',
    cluster_stats='cluster/{sample}_stats.csv',
    clustering_analysis='cluster/{sample}_analysis.csv',
    gaps='gaps/{sample}_gaps.npz',
    gap_stats='gaps/{sample}_stats.csv',
    variants='variants/{sample}_variants.txt'
  output:
    plot='plots/{sample}_summary.png',
    stats='stats/{sample}_summary.csv'
  params:
    switch=config['SWITCH'],
    switch_annotation=config['SWITCH_ANNOTATION'],
    max_gap=config['MAX_GAP'],
    weights=config['WEIGHTS']
  threads: 1
  resources:
    mem_mb=increase_mem,
    time='04:00:00',
    partition=get_partition
  conda:
    config['ENV']
  log: "logs/summary/{sample}.log"
  shell:
    r"""
    mkdir -p plots stats
    swibrid get_summary --sample {wildcards.sample} --figure {output.plot} --stats {output.stats} --filter {input.filter} --process {input.process} --info {input.info} --gaps {input.gaps} --clustering {input.clustering} --scanning {input.scanning} --cluster_stats {input.cluster_stats} --switch_anno {params.switch_annotation} --switch_coords {params.switch} --gap_stats {input.gap_stats} --max_gap {params.max_gap} --clustering_analysis {input.clustering_analysis} --variants {input.variants} --weights {params.weights} 2> {log}
    """


rule collect:
  input:
    expand("stats/{sample}_summary.csv", sample=config['SAMPLES']),
     expand("inserts/{sample}_inserts.tsv", sample=config['SAMPLES']),
     expand("cluster/{sample}_analysis.csv", sample=config['SAMPLES']),
  output:
    sample_stats='collect/{0}_stats.csv'.format(config['STUDY']),
    inserts='collect/{0}_inserts.xlsx'.format(config['STUDY']),
    cluster_stats='collect/{0}_clusters.xlsx'.format(config['STUDY'])
  params:
    samples=','.join(config['SAMPLES']),
  threads: 1
  resources:
    mem_mb=32000,
    time='04:00:00'
  conda:
    config['ENV']
  log: "logs/all/collect.log"
  shell:
    r"""
    mkdir -p collect
    swibrid collect_results --samples {params.samples} --sample_stats {output.sample_stats} --inserts {output.inserts} --cluster_stats {output.cluster_stats} 2> {log}
    """
